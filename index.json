[{"categories":["Programming"],"content":"为了学习C++顺便练手，听67建议先刷一遍洛谷的模板题来练手，在这里记录写题过程和总结。 ","date":"2021-10-16","objectID":"https://maxwellf1.github.io/2021-10-16/:0:0","series":null,"tags":["C++","luogu"],"title":"洛谷模板题目练习","uri":"https://maxwellf1.github.io/2021-10-16/"},{"categories":["Programming"],"content":"题目 P3367 【模板】并查集(2021/10/16)： 本题目理解起来不太难。主要是要看属于哪个集合，即找一个节点的根节点，在题解中有人提到了路径压缩，这个知识点我已经记不得了，在这里回忆一下并查集路径压缩 | 菜鸟教程 (runoob.com)。下面是AC的代码： #include \u003cbits/stdc++.h\u003eusing namespace std; int n, m, z, x, y, f[10001]; // 找父节点，也就是属于哪个集合 int find(int x){ if(f[x] == x){ return x; // 元素的父节点是自己，则返回本身 } else{ f[x] = find(f[x]);//直到找到父节点为止 } return f[x]; } void merge(int x, int y){ f[find(y)] = find(x); // 父节点一致 } void search(int x, int y){ if(find(x) == find(y)){ cout\u003c\u003c\"Y\"\u003c\u003cendl; }else{ cout\u003c\u003c\"N\"\u003c\u003cendl; } } int main(){ cin\u003e\u003en\u003e\u003em; int i; for(i = 1; i \u003c=n ; i++){ f[i] = i; //初始化并查集 } while(m--){ cin\u003e\u003ez\u003e\u003ex\u003e\u003ey; if(z == 1){ merge(x,y); } if(z == 2){ search(x,y); } } return 0; } P3366 【模板】最小生成树： 忘记怎么求最小生成树了，随便查了一篇博客图的最小生成树 - 智者侬哥 - 博客园 (cnblogs.com)学习，有kruskal和prim两种算法，两者好像都是运用贪心算法，kruskal是直接将边排序，然后选能够组成生成树的边，prim是不断找最小值添加新节点。前者好像适合稀疏图，后者适合稠密图，最小生成树算法 - Nemlit 的博客 - 洛谷博客 (luogu.com.cn)。正好在kruskal方法里判断是否需要添加某条边时也用到了并查集。 ","date":"2021-10-16","objectID":"https://maxwellf1.github.io/2021-10-16/:1:0","series":null,"tags":["C++","luogu"],"title":"洛谷模板题目练习","uri":"https://maxwellf1.github.io/2021-10-16/"},{"categories":["HPC","Tools"],"content":"在强师兄的推荐下了解到了Spack这款包管理的工具，好像在HPC领域用的很多。查阅了一些资料，在自己使用的过程中也遇到了一些问题。为了加深自己的认识，以及防止狗熊掰棒子的行为，在这里记录一下自己的理解以及遇到的问题。 ","date":"2021-10-12","objectID":"https://maxwellf1.github.io/2021-10-12/:0:0","series":null,"tags":["Spack"],"title":"Spack学习","uri":"https://maxwellf1.github.io/2021-10-12/"},{"categories":["HPC","Tools"],"content":"Spack ","date":"2021-10-12","objectID":"https://maxwellf1.github.io/2021-10-12/:1:0","series":null,"tags":["Spack"],"title":"Spack学习","uri":"https://maxwellf1.github.io/2021-10-12/"},{"categories":["HPC","Tools"],"content":"问题 Q: 自己想用spack安装新的软件，但显然自己只是个小用户，是没有sudo权限的。 A: 师兄给出的使用说明中，说可以自己安装spack后再将全局的spack配置为自己spack的上游。spack由于依赖的东西非常少，安装起来只需要根据官方文档的说明就可以完成。关于配置为上游的过程，在本地目录中我一直没有找到相关的配置文件。百度和Google上也没找到相关问题，后来在官方文档的Chaining Spack Installations部分找到了相关解答，需要自己在$SPACK_ROOT$/etc/spack/目录下新建文件upstreams.yaml，在填写上配置信息保存即可，花括号中的替换为对应想要设置为上游的spack路径。 upstreams:spack-instance-1:install_tree:{/path/to/other/spack}/opt/spackspack-instance-2:install_tree:{/path/to/another/spack}/opt/spack Q: Load不上Compilers A: 根据使用说明，spack find查看可用包后想load上gcc@7.5.0来用，之后紧接着load cmake@xxx，但却提示我 Error: No compilers for operating system centos 7 satisfy spec gcc\\@7.5.0 然后根据官方手册spack compilers查看可用编译器，发现没有load上gcc@7.5.0。使用spack compiler find之后也没也看到gcc-7.5.0在可用列表内。手册上说可以使用spack compiler find /path/来直接添加，但我并不知道gcc-7.5.0的安装位置。手册上也给出了这种情况的解决办法： spack load gcc@7.5.0 spack compiler find ==\u003e Added 1 new compiler to /home/fengguofeng/.spack/linux/compilers.yaml gcc@7.5.0 ==\u003e Compilers are defined in the following files: /home/fengguofeng/.spack/linux/compilers.yaml 再检查时可以看到已经load上了gcc@7.5.0，也没有后续报错，问题暂时解决。 另外，可以通过spack find --paths列出所有路径，也可以对于gcc，通过spack find -p gcc来查看指定包具体的路径。 Q: spack install时external packages相关报错，例如： Error:InstallError:cray-fftwisnotinstallable,youneedtospecifyitasanexternalpackageinpackages.yaml A: 有时候会出现，有时候不出现，即使是对于info中相关的external信息为False的情况。有点奇怪。比如可以装netlib-scalapack但没法install fftw。 怎么用spack+module啊，安装lmod提示失败。 ","date":"2021-10-12","objectID":"https://maxwellf1.github.io/2021-10-12/:2:0","series":null,"tags":["Spack"],"title":"Spack学习","uri":"https://maxwellf1.github.io/2021-10-12/"},{"categories":["HPC","Tools"],"content":"References Spack — Spack 0.16.3 documentation Spack - NERSC Documentation Spack 入门指南 – refraction-ray (re-ra.xyz) Installing HPCToolkit with Spack ","date":"2021-10-12","objectID":"https://maxwellf1.github.io/2021-10-12/:3:0","series":null,"tags":["Spack"],"title":"Spack学习","uri":"https://maxwellf1.github.io/2021-10-12/"},{"categories":["Tools"],"content":"没想到9.20的卜算7点多过去就只能去直播教室了，干脆在宿舍听。但是直播网站需要用到silverlight插件，目前这个插件只支持到win10版本好像，我的win11安装好后也仍然不能观看，仍无法识别，提示安装silverlight。一开始干脆准备装个win10的虚拟机，后来群里还好有大佬教我只需要在Edge中开启IE内核兼容即可。具体过程参考了技术丨如何在Chrome Edge开启IE兼容模式。即打开兼容模式之后再选择在IE模式下重新加载网页即可。 ","date":"2021-09-10","objectID":"https://maxwellf1.github.io/2021-09-10/:0:0","series":null,"tags":["Browsers"],"title":"浏览器设置","uri":"https://maxwellf1.github.io/2021-09-10/"},{"categories":["Tools"],"content":"前一段在新闻上看到了许多WSL2的新特性，于是就加入了Windows的开发者计划更新了一下dev版本的Win11，也学着玩玩WSL。因为感觉除了性能可能受影响，新版本的WSL2支持的GPU访问和WSLg对图形界面的支持基本上满足了我对linux的额外需求。 ","date":"2021-09-09","objectID":"https://maxwellf1.github.io/2021-09-09/:0:0","series":null,"tags":["WSL"],"title":"WSL相关操作","uri":"https://maxwellf1.github.io/2021-09-09/"},{"categories":["Tools"],"content":"问题 ","date":"2021-09-09","objectID":"https://maxwellf1.github.io/2021-09-09/:1:0","series":null,"tags":["WSL"],"title":"WSL相关操作","uri":"https://maxwellf1.github.io/2021-09-09/"},{"categories":["Tools"],"content":"位置移动 WSL默认装在C盘里，再在里面装各种工具后会导致空间占用很大，影响C盘空间。于是想通过某种方式将其移动到另一块比较空的磁盘中。网上查到可以直接通过wsl指令来进行压缩、移动、解压的过程(例如wsl –export和wsl –import进行打包并自定义目录安装)，然而不知道是否我操作出了问题，没有成功实现。后来查到了DDoSolitary/LxRunOffline: A full-featured utility for managing Windows Subsystem for Linux (WSL) (github.com)这款软件，可以很方便的通过一些指令来对WSL进行管理，它可以安装任意发行版到任意目录，还可以对已经安装的WSL进行转移、备份、设置默认用户和修改环境变量等操作。安装以及使用过程参考了LxRunOffline 使用教程 - WSL 自定义安装、备份 - P3TERX ZONE上的说明(安装后记得将路径添加到系统环境变量中)。 以下命令均在以管理员权限运行的Windows Powershell下执行。 查看系统中已经安装的WSL： lxrunoffline l 将WSL镜像移动到指定目录： lxrunoffline m -n \u003cWSL名称\u003e -d \u003c路径\u003e 查看路径，进行确认： lxrunoffline -di -n \u003cWSL名称\u003e 然而初次执行移动命令的时候有报错： [ERROR] Couldn't set the case sensitive attribute of the directory \"...... Reason: Indicates that the directory trying to be deleted is not empty. 看起来是没有默认设为大小写敏感，于是尝试在Powershell中使用fsutil指令尝试enable大小写敏感，然而手动执行的时候仍然会报“文件夹不为空”的错误。后来参考迁移WSL时的报错：0x80073d21 此应用的发布者不允许将其移动到其他位置-dtcms模板网 (dtmao.cc)的解决办法，换了另一个版本的LxRunOffline,成功解决了报错问题。移动之后就是把C盘中对应文件夹下的镜像文件ext4.vhdx移动到了指定目录下，然而移动完成后发现无法打开移动后的WSL子系统，后来通过重启电脑解决了这个问题。 ","date":"2021-09-09","objectID":"https://maxwellf1.github.io/2021-09-09/:1:1","series":null,"tags":["WSL"],"title":"WSL相关操作","uri":"https://maxwellf1.github.io/2021-09-09/"},{"categories":["Tools"],"content":"拒决访问 迁移位置之后，多次出现了运行wsl时出现拒绝访问的问题。首先去“启用或关闭Windows功能”中检查了一下WSL相关功能是否正常启用，即“适用于Linux的Windows子系统、虚拟机平台”。然后去网上查询了相关资料，有的人说是因为某些原因导致只有在以管理员权限运行的powershell或者cmd中才能打开，尝试之后发现这并不是我想要的解决方案，没有变化。 又看到是因为hyper-V功能问题导致的，想到不小心使用了一下VMware，听说WSL和VMware是不兼容的，怀疑是自动把我hyper-V给关闭了。于是去百度上搜索了一下重启的命令。第一条是关闭第二条是重新打开。 bcdedit /set hypervisorlaunchtype off bcdedit /set hypervisorlaunchtype auto 重启之后发现仍然没有解决问题，又打开“启用或关闭Windows功能”中查看，突然发现列表里根本没有Hyper-V相关的选项。我当时就是满脸问号，🤣？？？我Hyper-V呢？？？难不成用一下VMware还能自动把我Hyper-V给卸载了？表示无语，根据网上的教程安装并启用了一下Hyper-V。暂时解决了这个问题。 但就在一天之后，又出现了拒绝访问的问题。这次用前面的方法是怎么都解决不了了。我尝试重新安了另一个子系统，发现可以正常打开，所以怀疑是否是我移动ext4.vhdx文件后导致该文件相关权限出了问题才拒绝访问。于是又去网上查询了相关解答。在微软的官方论坛中找到了类似的问题。打开属性-\u003e安全后果不其然，我的User对该镜像文件的权限只有修改，编辑后打开User的“完全控制”权限。终于解决了这个问题。 ","date":"2021-09-09","objectID":"https://maxwellf1.github.io/2021-09-09/:1:2","series":null,"tags":["WSL"],"title":"WSL相关操作","uri":"https://maxwellf1.github.io/2021-09-09/"},{"categories":["HPC"],"content":"对于新的高性能架构，通常能源效益应该放在设计的第一位，之后要紧接考虑的是可编程性和应用范围。(performance goal: extremscale, 10^18)。 ","date":"2021-08-28","objectID":"https://maxwellf1.github.io/2021-08-28/:0:0","series":null,"tags":["Udacity","CUDA","HPC"],"title":"Udacity CS344-Intro to Parallel Programming-Unit2-GPU Hardware and Parallel Communication Patterns","uri":"https://maxwellf1.github.io/2021-08-28/"},{"categories":["HPC"],"content":"Communication Patterns 并行计算都是关于很多线程协同工作来解决问题，关键是协同工作，而协同工作与通信有关，在CUDA中，通信主要发生在内存相关。 ","date":"2021-08-28","objectID":"https://maxwellf1.github.io/2021-08-28/:1:0","series":null,"tags":["Udacity","CUDA","HPC"],"title":"Udacity CS344-Intro to Parallel Programming-Unit2-GPU Hardware and Parallel Communication Patterns","uri":"https://maxwellf1.github.io/2021-08-28/"},{"categories":["HPC"],"content":"Map and Gather Map：对每一个数据进行同样的函数或计算任务。即每个任务在内存中特定位置读取和写入，输出输出之间是一对一的关系。 Gather: 每个线程计算并存储一系列元素的值，并输出一个计算结果，即多-\u003e一/多，例如求平均值。 ","date":"2021-08-28","objectID":"https://maxwellf1.github.io/2021-08-28/:1:1","series":null,"tags":["Udacity","CUDA","HPC"],"title":"Udacity CS344-Intro to Parallel Programming-Unit2-GPU Hardware and Parallel Communication Patterns","uri":"https://maxwellf1.github.io/2021-08-28/"},{"categories":["HPC"],"content":"Scatter Tasks compute where to write output。可以理解为Gather的逆操作，每个并行任务需要将结果写入不同的地方或多个地方，而要写入哪个地方是该任务计算得出的。 ","date":"2021-08-28","objectID":"https://maxwellf1.github.io/2021-08-28/:1:2","series":null,"tags":["Udacity","CUDA","HPC"],"title":"Udacity CS344-Intro to Parallel Programming-Unit2-GPU Hardware and Parallel Communication Patterns","uri":"https://maxwellf1.github.io/2021-08-28/"},{"categories":["HPC"],"content":"Stencil(模板) Tasks read input from a fixed neighborhood in an array. Data Reuse! 以固定的格式(模板)来更新元素。例如：2D冯诺依曼模板，2D Moore pattern。相邻操作会有重叠，即数据重用，很多线程访问并计算相同的数据。每个元素被访问的数量与模板中元素数量相同，例如2D Moore pattern中每个数据会被访问9次。 ","date":"2021-08-28","objectID":"https://maxwellf1.github.io/2021-08-28/:1:3","series":null,"tags":["Udacity","CUDA","HPC"],"title":"Udacity CS344-Intro to Parallel Programming-Unit2-GPU Hardware and Parallel Communication Patterns","uri":"https://maxwellf1.github.io/2021-08-28/"},{"categories":["HPC"],"content":"Transpose(转置) Tasks re-order data elements in memory ","date":"2021-08-28","objectID":"https://maxwellf1.github.io/2021-08-28/:1:4","series":null,"tags":["Udacity","CUDA","HPC"],"title":"Udacity CS344-Intro to Parallel Programming-Unit2-GPU Hardware and Parallel Communication Patterns","uri":"https://maxwellf1.github.io/2021-08-28/"},{"categories":["HPC"],"content":"Parallel Communitcation Patterns Recap ","date":"2021-08-28","objectID":"https://maxwellf1.github.io/2021-08-28/:1:5","series":null,"tags":["Udacity","CUDA","HPC"],"title":"Udacity CS344-Intro to Parallel Programming-Unit2-GPU Hardware and Parallel Communication Patterns","uri":"https://maxwellf1.github.io/2021-08-28/"},{"categories":["HPC"],"content":"GPU Hardware 我们应该考虑什么？以下这些问题也反映出了并行程序对于性能的设计以及安全操作的要求会更高，我们要结合GPU硬件架构特性来考虑。 ","date":"2021-08-28","objectID":"https://maxwellf1.github.io/2021-08-28/:2:0","series":null,"tags":["Udacity","CUDA","HPC"],"title":"Udacity CS344-Intro to Parallel Programming-Unit2-GPU Hardware and Parallel Communication Patterns","uri":"https://maxwellf1.github.io/2021-08-28/"},{"categories":["HPC"],"content":"Summary of programming model 线程的关键点是它们以线程块的形式出现，一个线程块是一组合作解决次要问题的线程。GPU程序会启动多个线程来运行一个kernel，然后它们都运行到完成并退出。之后程序可以启动多个线程来运行下一个kernel。 ","date":"2021-08-28","objectID":"https://maxwellf1.github.io/2021-08-28/:2:1","series":null,"tags":["Udacity","CUDA","HPC"],"title":"Udacity CS344-Intro to Parallel Programming-Unit2-GPU Hardware and Parallel Communication Patterns","uri":"https://maxwellf1.github.io/2021-08-28/"},{"categories":["HPC"],"content":"SM SM是GPU中很高层的核心结构，由多个SP(streaming processor, aka CUDA core，最后具体的指令和任务都是在SP上处理)加上其它一些资源组成。SM中register和shared memory是很宝贵的资源，CUDA将这些资源分配给所有驻留在SM中的线程，这些有效的资源使得每个SM中active warps有非常严格的限制，即限制了并行能力 。 一个SP可以执行一个thread，但是实际上并不是所有的thread能够在同一时刻执行。Nvidia把32个threads组成一个warp，warp是调度和运行的基本单元。warp中所有threads并行的执行相同的指令。一个warp需要占用一个SM运行，多个warps需要轮流进入SM。由SM的硬件warp scheduler负责调度。目前每个warp包含32个threads（Nvidia保留修改数量的权利）。所以，一个GPU上resident thread最多只有 SM*warp个。 ———————————————— 版权声明：本文为CSDN博主「ZhangJunior」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。 原文链接：https://blog.csdn.net/junparadox/article/details/50540602 GPU负责给SM来分配块，所有SM都并行运行，根据定义，一个线程块只能在一个SM上运行，而一个SM可能会运行多个线程块。 CUDA对线程块将在何时、何处运行不作保证，事实上这是CUDA的一个巨大优势，是能够运行很快的原因： Advantages Consequences flexibility-efficiency(由于灵活性，硬件可以真正有效的运行，例如一个线程块快速完成后SM可以立即安排另一个线程块，而无需等待其他线程块完成) 无法假设哪个block在哪个SM上运行 scalability: 因为无法指定线程块在哪运行或者多少线程块会同时运行 无法获得块之间任何明确的通信，可能会造成一些不好的后果(eg: 死锁) ","date":"2021-08-28","objectID":"https://maxwellf1.github.io/2021-08-28/:2:2","series":null,"tags":["Udacity","CUDA","HPC"],"title":"Udacity CS344-Intro to Parallel Programming-Unit2-GPU Hardware and Parallel Communication Patterns","uri":"https://maxwellf1.github.io/2021-08-28/"},{"categories":["HPC"],"content":"So what does CUDA guarantee? 某块中的所有线程都保证同时在同一个SM上运行。 所有内核中的快都在下个内核中任何块启动前结束。 ","date":"2021-08-28","objectID":"https://maxwellf1.github.io/2021-08-28/:2:3","series":null,"tags":["Udacity","CUDA","HPC"],"title":"Udacity CS344-Intro to Parallel Programming-Unit2-GPU Hardware and Parallel Communication Patterns","uri":"https://maxwellf1.github.io/2021-08-28/"},{"categories":["HPC"],"content":"GPU Memory Model 每个线程可以访问local memory，这是该线程专用的内存，就像其局部变量，线程可以从局部存储器读取和写入。一个线程块中的线程可以访问shared memory，它是在SM上的少量内存。任何时间整个系统中的每个线程都可以访问global memory(即通常所说的显存)。 ","date":"2021-08-28","objectID":"https://maxwellf1.github.io/2021-08-28/:2:4","series":null,"tags":["Udacity","CUDA","HPC"],"title":"Udacity CS344-Intro to Parallel Programming-Unit2-GPU Hardware and Parallel Communication Patterns","uri":"https://maxwellf1.github.io/2021-08-28/"},{"categories":["HPC"],"content":"Synchronization 线程需要进行同步，以避免出现后面的线程在前面的线程计算/写入结果之前就进行读取的情况。 Barrier 同步中最简单的一种形式。即设置一个点，程序中的线程会到这点停止并等待，直到所有线程都达到屏障点。 eg:","date":"2021-08-28","objectID":"https://maxwellf1.github.io/2021-08-28/:2:5","series":null,"tags":["Udacity","CUDA","HPC"],"title":"Udacity CS344-Intro to Parallel Programming-Unit2-GPU Hardware and Parallel Communication Patterns","uri":"https://maxwellf1.github.io/2021-08-28/"},{"categories":["HPC"],"content":"CUDA Programming Model CUDA的核心是计算层次。即线程、线程块和内核。以及与其对应的内存空间层次结构：本地、共享和全局内存。还有同步原语，例如同步线程的barrier，以及先后两个内核之间的默认隐式的barrier。 ","date":"2021-08-28","objectID":"https://maxwellf1.github.io/2021-08-28/:2:6","series":null,"tags":["Udacity","CUDA","HPC"],"title":"Udacity CS344-Intro to Parallel Programming-Unit2-GPU Hardware and Parallel Communication Patterns","uri":"https://maxwellf1.github.io/2021-08-28/"},{"categories":["HPC"],"content":"Writing Efficient Programs 编写GPU程序时应当牢记几点原则： ","date":"2021-08-28","objectID":"https://maxwellf1.github.io/2021-08-28/:3:0","series":null,"tags":["Udacity","CUDA","HPC"],"title":"Udacity CS344-Intro to Parallel Programming-Unit2-GPU Hardware and Parallel Communication Patterns","uri":"https://maxwellf1.github.io/2021-08-28/"},{"categories":["HPC"],"content":"1.Maximize arithmetric intensity GPU的计算能力很强。高端GPU每秒可以进行超过3 trillion次数(TFLOPS)的数学计算。如果让这些计算单元等待太久是很低效的。arithmetric intensity基本可以理解为math/memory，即访问的单位内存上我们可以进行的数学计算量。所以我们可以通过增大分子或者减小分母来提高性能。 Minimize time spent on memory 把常用的数据放在更快的内存层次中。 注意shared mem是在一个block内部共享的，生命周期也对应于它所在的block，因此计算结果要存回到全局内存中。 合并对全局内存的访问(coalesce global memory accesses) 线程读取/写入连续的全局内存位置是最高效的。 读写冲突： 可以通过同步、原子操作来解决。原子操作有加、减、异或等，其中一个特别有趣的操作是atomicCAS(Compare and Swap)。 但原子操作是有很明显的缺陷，首先它只支持某些特定的运算和数据类型(例如没有求余，而且主要是对整型数据)，其实可以用CAS来实现各种不原生支持的操作(但效率可能会很低)；而且用原子操作仍然是没有顺序约束的，而浮点数的运算是没有结合律的，精度可能会由于不同的顺序做不同的舍入处理；GPU在这种情况下强制线程串行化的访问内存，这样速度会很慢。 ","date":"2021-08-28","objectID":"https://maxwellf1.github.io/2021-08-28/:3:1","series":null,"tags":["Udacity","CUDA","HPC"],"title":"Udacity CS344-Intro to Parallel Programming-Unit2-GPU Hardware and Parallel Communication Patterns","uri":"https://maxwellf1.github.io/2021-08-28/"},{"categories":["HPC"],"content":"2. Avoid thread divergence 就是说要避免让处于同一个线程块中的线程执行不同的操作，因为这样会降低速度，硬件中的有些线程运行而有些闲置。也许可以讲条件语句进行拆分，根据条件分成独立的kernel。 ","date":"2021-08-28","objectID":"https://maxwellf1.github.io/2021-08-28/:3:2","series":null,"tags":["Udacity","CUDA","HPC"],"title":"Udacity CS344-Intro to Parallel Programming-Unit2-GPU Hardware and Parallel Communication Patterns","uri":"https://maxwellf1.github.io/2021-08-28/"},{"categories":["HPC"],"content":"Summary ","date":"2021-08-28","objectID":"https://maxwellf1.github.io/2021-08-28/:4:0","series":null,"tags":["Udacity","CUDA","HPC"],"title":"Udacity CS344-Intro to Parallel Programming-Unit2-GPU Hardware and Parallel Communication Patterns","uri":"https://maxwellf1.github.io/2021-08-28/"},{"categories":["HPC"],"content":"Problem Set 2 A parallel bluring algorithm. ","date":"2021-08-28","objectID":"https://maxwellf1.github.io/2021-08-28/:5:0","series":null,"tags":["Udacity","CUDA","HPC"],"title":"Udacity CS344-Intro to Parallel Programming-Unit2-GPU Hardware and Parallel Communication Patterns","uri":"https://maxwellf1.github.io/2021-08-28/"},{"categories":["CUDA"],"content":"Windows 在Windows上安装CUDA只需要根据官网上的指南安装对应的版本并添加到系统环境变量里就可以正常使用了。但是需要配合Visual Studio，感觉这个软件过于庞大繁杂。 ","date":"2021-08-22","objectID":"https://maxwellf1.github.io/2021-08-22/:1:0","series":null,"tags":["CUDA","Environment"],"title":"CUDA Environment Configuration","uri":"https://maxwellf1.github.io/2021-08-22/"},{"categories":["CUDA"],"content":"命令行设置 希望能够从头开始熟悉CUDA的编写、编译流程等，希望能够不用Visual Studio而是可以像Linux下直接通过命令行编译.cu文件并生成可执行文件，通过查询，根据1完成了该配置。配置过程如下： 首先要将VS的VC编译器放在环境变量中，对于我的64位系统而言要将用于x64的VC编译器放在环境变量中： 在系统变量Path中添加如下的两个条目： C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\bin\\Hostx64\\x64 C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Common7\\IDE 在系统变量中新建一个叫LIB的变量，并为其添加三个条目： C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\lib\\x64 C:\\Program Files (x86)\\Windows Kits\\10\\Lib\\10.0.15063.0\\ucrt\\x64 C:\\Program Files (x86)\\Windows Kits\\10\\Lib\\10.0.15063.0\\um\\x64 在系统变量中新建一个叫INCLUDE的变量，为其添加两个条目。 C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\include C:\\Program Files (x86)\\Windows Kits\\10\\Include\\10.0.15063.0\\ucrt 以上三个步骤的作用其实是让 VC 编译器脱离 Visual Studio IDE 环境生效，也就是说可以让 VC 编译器 cl.exe 在命令行下编译 .cpp 或 .c 文件。因为 nvcc 编译器虽说是 .cu 的编译器，但是它还是要调用 VC 编译器 cl.exe 来对 .cu 文件进行编译，这也就是说为什么 CUDA 离不开 Visual Studio，而在其他平台上，比如 Linux，可能 CUDA 需要调用 gcc 或 g++ 编译器来完成对 .cu 文件的编译。经过这个配置过程后就可以通过nvcc指令加上相关参数来编译执行代码了。(比如我现在的thinkpadt470p需要加上-arch=compute_35的选项，因为硬件和默认的编译选项不匹配)。 ","date":"2021-08-22","objectID":"https://maxwellf1.github.io/2021-08-22/:1:1","series":null,"tags":["CUDA","Environment"],"title":"CUDA Environment Configuration","uri":"https://maxwellf1.github.io/2021-08-22/"},{"categories":["CUDA"],"content":"WSL 由于想用到linux相关的命令行，而且觉得从头开始编写和编译能够理解的更清楚，但电脑上又没有双系统。我从CUDA的官方文档中看到了对WSL的支持，就去网上搜索了相关的教程。一开始安装好了CUDA，但是nvidia-smi无法访问显卡，以为是WSL设置的原因，搞了好久。最后又重读了一遍CUDA的官方文档发现对Windows系统的版本有要求，最好是20145以上的，但我查看自己的windows10系统，居然只是19xxx，而且检查过后居然没有可用的更新。 后来发现必须加入Windows预览体验计划才能更新这些版本，自己加入并选择DEV Channel后居然自动给我更新了win11…只能硬着头皮上了，感觉自己的电脑配置不一定够用，安好之后又按照官方文档重来一遍，这次可以正常在WSL访问到GPU并使用CUDA了。不得不说win11长得属实有点像MACOS啊，而且这次警示我一定不要先瞎去网上找资料，RTFM。 ","date":"2021-08-22","objectID":"https://maxwellf1.github.io/2021-08-22/:2:0","series":null,"tags":["CUDA","Environment"],"title":"CUDA Environment Configuration","uri":"https://maxwellf1.github.io/2021-08-22/"},{"categories":["CUDA"],"content":"一些问题 明明安装好了CUDA，却无法使用NVCC的相关命令： 这通常是没有配置好环境变量导致的。 例如在Linux系统下，可以打开~/.bahsrc，在其中添加环境变量 export LD_LIBRARY_PATH=/usr/local/cuda/lib export PATH=$PATH:/usr/local/cuda/bin 并执行source ~/.bashrc使得环境变量生效。 ","date":"2021-08-22","objectID":"https://maxwellf1.github.io/2021-08-22/:3:0","series":null,"tags":["CUDA","Environment"],"title":"CUDA Environment Configuration","uri":"https://maxwellf1.github.io/2021-08-22/"},{"categories":["CUDA"],"content":"参考文献 Windows 下在命令行编译 CUDA 文件 ","date":"2021-08-22","objectID":"https://maxwellf1.github.io/2021-08-22/:4:0","series":null,"tags":["CUDA","Environment"],"title":"CUDA Environment Configuration","uri":"https://maxwellf1.github.io/2021-08-22/"},{"categories":["HPC"],"content":"受功耗限制，不能无限提高单块芯片的频率，不如用很多处理器来进行计算。 Seymour Cray: Would you rather plow a field with two strong oxen or 1024 chickens? ","date":"2021-08-21","objectID":"https://maxwellf1.github.io/2021-08-21/:0:0","series":null,"tags":["Udacity","CUDA","HPC"],"title":"Udacity CS344-Intro to Parallel Programming-Unit1-The GPU Programming Model","uri":"https://maxwellf1.github.io/2021-08-21/"},{"categories":["HPC"],"content":"What kind of Processors are we Building Major design constraint: Power. 不采用CPU是因为CPU有复杂的控制单元硬件，这允许性能的灵活性，但随着控制硬件变得复杂，耗电量也会增高。不如采用更简单的结构，并将这些重复的简单结构放在一个芯片中，但这需要新的编程模型。 需要优化什么？ Latency(time, seconds): 即最大程度缩小执行时间。传统的CPU主要是在这一点，试图最小化每个任务具体消耗的时间。 Throughout(stuff/time, jobs/hour): 每个单位时间完成的工作量。GPU主要来优化吞吐量。 GPU的设计特点： GPU有很多简单计算单位，可以在一起执行大量的计算(GPU一般愿意来用更简单的控制硬件来换取更多的计算单元，这也对程序员的要求更高)。 GPU有显式编程模型，在给机器编写程序时，我们知道我们有很多处理器，并且根据这一点进行编程。 GPU为吞吐量进行优化，而不是延迟(它愿意接受任何单一个体计算增加的延迟来换取单位时间内进行更多的计算)。 ","date":"2021-08-21","objectID":"https://maxwellf1.github.io/2021-08-21/:1:0","series":null,"tags":["Udacity","CUDA","HPC"],"title":"Udacity CS344-Intro to Parallel Programming-Unit1-The GPU Programming Model","uri":"https://maxwellf1.github.io/2021-08-21/"},{"categories":["HPC"],"content":"CUDA 如果还是普通的c语言编程，只能在CPU(“host”)上运行，而CUDA帮助我们在GPU(“device”)上进行编程。 此图大概说明了CUDA的整体工作结构。注意，GPU只能响应CPU发送数据或接收数据的请求而不能initiate这些请求。 ","date":"2021-08-21","objectID":"https://maxwellf1.github.io/2021-08-21/:2:0","series":null,"tags":["Udacity","CUDA","HPC"],"title":"Udacity CS344-Intro to Parallel Programming-Unit1-The GPU Programming Model","uri":"https://maxwellf1.github.io/2021-08-21/"},{"categories":["HPC"],"content":"A CUDA Program 注意图中的通信很可能是有很大开销的，所以要注意编程中的计算和通信的比例。 ","date":"2021-08-21","objectID":"https://maxwellf1.github.io/2021-08-21/:2:1","series":null,"tags":["Udacity","CUDA","HPC"],"title":"Udacity CS344-Intro to Parallel Programming-Unit1-The GPU Programming Model","uri":"https://maxwellf1.github.io/2021-08-21/"},{"categories":["HPC"],"content":"What is the GPU good at? 有效的启动大量线程(“The GPU does not even get out of bed in the morning for fewer than a thousand threads”). 同时并行运行大量线程。 ","date":"2021-08-21","objectID":"https://maxwellf1.github.io/2021-08-21/:2:2","series":null,"tags":["Udacity","CUDA","HPC"],"title":"Udacity CS344-Intro to Parallel Programming-Unit1-The GPU Programming Model","uri":"https://maxwellf1.github.io/2021-08-21/"},{"categories":["HPC"],"content":"GPU Calculation ","date":"2021-08-21","objectID":"https://maxwellf1.github.io/2021-08-21/:3:0","series":null,"tags":["Udacity","CUDA","HPC"],"title":"Udacity CS344-Intro to Parallel Programming-Unit1-The GPU Programming Model","uri":"https://maxwellf1.github.io/2021-08-21/"},{"categories":["HPC"],"content":"GPU Code: A High-level View 我们启动的每一个线程知道自己的编号，即有线程索引。大概流程是先编写在一个线程上运行的kernel，然后会启动许多线程，每个线程独立运行那个内核。 ","date":"2021-08-21","objectID":"https://maxwellf1.github.io/2021-08-21/:3:1","series":null,"tags":["Udacity","CUDA","HPC"],"title":"Udacity CS344-Intro to Parallel Programming-Unit1-The GPU Programming Model","uri":"https://maxwellf1.github.io/2021-08-21/"},{"categories":["HPC"],"content":"Squaring Numbers Using CUDA #include \u003cstdio.h\u003e __global__ void square(float* d_out, float* d_in){ int idx = threadIdx.x; float f = d_in[idx]; d_out[idx] = f * f; } int main(int argc, char** argv){ const int ARRAY_SIZE = 64; const int ARRAY_BYTES = ARRAY_SIZE * sizeof(float); // generate the input array on the host float h_in[ARRAY_SIZE]; for(int i = 0; i\u003cARRAY_SIZE; i++){ h_in[i] = float(i); } float h_out[ARRAY_SIZE]; // declare GPU memory pointers float* d_in; float* d_out; // allocate GPU memory cudaMalloc((void **) \u0026d_in, ARRAY_BYTES); cudaMalloc((void **) \u0026d_out, ARRAY_BYTES); // transfer the array to GPU cudaMemcpy(d_in, h_in, ARRAY_BYTES, cudaMemcpyHostToDevice); // launch the kernel square\u003c\u003c\u003c1, ARRAY_SIZE\u003e\u003e\u003e(d_out, d_in); // copy back the result array to the GPU cudaMemcpy(h_out, d_out, ARRAY_BYTES, cudaMemcpyDeviceToHost); // print out the resulting array for(int i=0; i\u003cARRAY_SIZE; i++){ printf(\"%f\", h_out[i]); printf(((i % 4) != 3) ? \"\\t\" : \"\\n\"); } // free GPU memory allocation cudaFree(d_in); cudaFree(d_out); return 0; } 这是一个计算平方的程序，但可以大概看出CUDA程序的结构。 Configuring the kernel call square.cu中我们启动了一个块，这个块含有64个线程。但参数是我们可以自行调整的。 需要注意，可以同时运行很多块，而且每个块是有支持的线程上限的，例如512,1024。 Kernel\u003c\u003c\u003cGrid of Blocks, Block of Threads\u003e\u003e\u003e(...) CUDA不仅支持1维的线程块，还支持2、3维的线程块，同样的我们也可以把线程块安排到1、2、3维的网格中(当我们不指定时，默认为1维)。我们需要三维结构时，可以通过如下方式借助dim3格式来初始化(我们不指定时则默认y,z为1)。 dim3(x,y,z) dim3(w,1,1) == dim3(w) == w square\u003c\u003c\u003c1,64\u003e\u003e\u003e == square\u003c\u003c\u003cdim3(1,1,1), dim3(64,1,1)\u003e\u003e\u003e 所以通用的内核启动可以看成如下三个参数的形式： square\u003c\u003c\u003cdim3(bx,by,bz), dim3(tx,ty,tz), shmem\u003e\u003e\u003e(...) 其中第一个参数是网格块的维数(即网格中有bx×by×bz个线程块)，每个线程块的维数由第二个参数指定，第三个参数是以字节为单位的给每个线程块分配的共享内存量(默认为0)。当我们的问题有多个维度时，拥有多维网格和块是很方便的。 ","date":"2021-08-21","objectID":"https://maxwellf1.github.io/2021-08-21/:3:2","series":null,"tags":["Udacity","CUDA","HPC"],"title":"Udacity CS344-Intro to Parallel Programming-Unit1-The GPU Programming Model","uri":"https://maxwellf1.github.io/2021-08-21/"},{"categories":["HPC"],"content":"Map ","date":"2021-08-21","objectID":"https://maxwellf1.github.io/2021-08-21/:4:0","series":null,"tags":["Udacity","CUDA","HPC"],"title":"Udacity CS344-Intro to Parallel Programming-Unit1-The GPU Programming Model","uri":"https://maxwellf1.github.io/2021-08-21/"},{"categories":["HPC"],"content":"Summary ","date":"2021-08-21","objectID":"https://maxwellf1.github.io/2021-08-21/:5:0","series":null,"tags":["Udacity","CUDA","HPC"],"title":"Udacity CS344-Intro to Parallel Programming-Unit1-The GPU Programming Model","uri":"https://maxwellf1.github.io/2021-08-21/"},{"categories":["HPC"],"content":"Problem set 1 将彩色照片变为黑白的，这次作业比较简单。但自己花费了很多时间在环境搭建上，没想到Windows居然搞好了，但是不想用过于庞大繁琐的Visual Studio，就花了很多时间在WSL2+CUDA的配置上，但现在还是没有完全配置好环境，只能继续用IDE了。此外，某位大佬用Colab好像配了个jupeternotebook那样的环境，只要根据报错将makefile里面的compute_30改为compute_35就可以正常使用了。 下面是需要编写的student.cu的代码： // Homework 1 // Color to Greyscale Conversion //A common way to represent color images is known as RGBA - the color //is specified by how much Red, Grean and Blue is in it. //The 'A' stands for Alpha and is used for transparency, it will be //ignored in this homework. //Each channel Red, Blue, Green and Alpha is represented by one byte. //Since we are using one byte for each color there are 256 different //possible values for each color. This means we use 4 bytes per pixel. //Greyscale images are represented by a single intensity value per pixel //which is one byte in size. //To convert an image from color to grayscale one simple method is to //set the intensity to the average of the RGB channels. But we will //use a more sophisticated method that takes into account how the eye //perceives color and weights the channels unequally. //The eye responds most strongly to green followed by red and then blue. //The NTSC (National Television System Committee) recommends the following //formula for color to greyscale conversion: //I = .299f * R + .587f * G + .114f * B //Notice the trailing f's on the numbers which indicate that they are //single precision floating point constants and not double precision //constants. //You should fill in the kernel as well as set the block and grid sizes //so that the entire image is processed. #include \"utils.h\" __global__ void rgba_to_greyscale(const uchar4* const rgbaImage, unsigned char* const greyImage, int numRows, int numCols) { //TODO //Fill in the kernel to convert from color to greyscale //the mapping from components of a uchar4 to RGBA is: // .x -\u003e R ; .y -\u003e G ; .z -\u003e B ; .w -\u003e A // //首先找到本线程对应需要处理的像素 int x = threadIdx.x + blockDim.x*blockIdx.x; int y = threadIdx.y + blockDim.y*blockIdx.y; if(Idx \u003c numCols * numRows){ uchar4 rgba = rgbaImage[Idx]; //The output (greyImage) at each pixel should be the result of //applying the formula: output = .299f * R + .587f * G + .114f * B; //Note: We will be ignoring the alpha channel for this conversion greyImage[Idx] = 0.299f*rgba.x + 0.587f*rgba.y + 0.114f * rgba.z; } //First create a mapping from the 2D block and grid locations //to an absolute 2D location in the image, then use that to //calculate a 1D offset void your_rgba_to_greyscale(const uchar4 * const h_rgbaImage, uchar4 * const d_rgbaImage, unsigned char* const d_greyImage, size_t numRows, size_t numCols) { //You must fill in the correct sizes for the blockSize and gridSize //currently only one block with one thread is being launched const dim3 blockSize(16, 16, 1); //TODO const dim3 gridSize( (numCols+blockSize.x-1)/blockSize.x,(numRows+blockSize.y-1)/blockSize.y, 1); //TODO //const dim3 gridSize( floor(numCols/16)+1,floor(numRows/16)+1, 1); //TODO rgba_to_greyscale\u003c\u003c\u003cgridSize, blockSize\u003e\u003e\u003e(d_rgbaImage, d_greyImage, numRows, numCols); cudaDeviceSynchronize(); checkCudaErrors(cudaGetLastError()); } ","date":"2021-08-21","objectID":"https://maxwellf1.github.io/2021-08-21/:6:0","series":null,"tags":["Udacity","CUDA","HPC"],"title":"Udacity CS344-Intro to Parallel Programming-Unit1-The GPU Programming Model","uri":"https://maxwellf1.github.io/2021-08-21/"},{"categories":["HPC"],"content":"Exercise ","date":"2021-08-21","objectID":"https://maxwellf1.github.io/2021-08-21/:7:0","series":null,"tags":["Udacity","CUDA","HPC"],"title":"Udacity CS344-Intro to Parallel Programming-Unit1-The GPU Programming Model","uri":"https://maxwellf1.github.io/2021-08-21/"},{"categories":["HPC"],"content":"1. about threadIdx, blockIdx , blockDim and gridDim 关于这些参数之间的关系，启动kernel的时候我们要指定blockSize和gridSize, 填充的时候应该是按照x, y, z的顺序(官方文档上的图好像是这样的)。 gridDim： 指定grid维度，类型为dim3 blockDIm： 指定block维度，类型为dim3 blockIdx: 指定grid内block索引号，类型为uint3 threadIdx 指定block内thread索引号，类型为uint3 warpsize： 指定warp内thread数量，类型为int The index of a thread and its thread ID relate to each other in a straightforward way: For a one-dimensional block, they are the same; for a two-dimensional block of size (Dx, Dy),the thread ID of a thread of index (x, y) is (x + y Dx); for a three-dimensional block of size (Dx, Dy, Dz), the thread ID of a thread of index (x, y, z) is (x + y Dx + z Dx Dy). 下面作为练习，来求各种情况下的真正的threadIdx： // 1D grid of 1D blocks __device__ int getGlobalIdx_1D_1D(){ return blockIdx.x*blockDim.x + threadIdx.x; } // 1D grid of 2D blocks __device__ int getGlobalIdx_1D_2D(){ return blockIdx.x*blockDim.x*blockDim.y + threadIdx.y*blockDim.x + threadIdx.x; } // 1D grid of 3D blocks __device__ int getGlobalIdx_1D_3D(){ return blockIdx.x*blockDim.x*blockDim.y*blockDim.z + threadIdx.z*blockDim.x*blockDim.y + threadIdx.y*blockDim.x + threadIdx.x; } // 2D grid of 1D blocks __device__ int getGlobalIdx_2D_1D(){ int blockId = blockIdx.y*gridDim.x + blockIdx.x; int threadId = blockId*blockDim.x + threadIdx.x; return threadId; } // 2D grid of 2D blocks __device__ int getGlobalIdx_2D_2D(){ int blockId = blockIdx.y*gridDim.x + blockIdx.x; int threadId = blockId*blockDim.x*blockDim.y+ threadIdx.y*blockDim.x+ threadIdx.x; return threadId; } // 2D grid of 3D blocks __device__ int getGlobalIdx_2D_3D(){ int blockId = blockIdx.y*gridDim.x + blockIdx.x; int threadId = blockId*blockDim.x*blockDim.y*blockDim.z+ threadIdx.z*blockDim.x*blockDim.y+ threadIdx.y*blockDim.x+ threadIdx.x; return threadId; } // 3D grid of 1D blocks __device__ int getGlobalIdx_3D_1D(){ int blockId = blockIdx.z*gridDim.x*gridDim.y + blockIdx.y*gridDim.x+ blockIdx.x; int threadId = blockId*blockDim.x + threadIdx.x; return threadId; } // 3D grid of 2D blocks __device__ int getGlobalIdx_3D_2D(){ int blockId = blockIdx.z*gridDim.x*gridDim.y + blockIdx.y*gridDim.x+ blockIdx.x; int threadId = blockId*blockDim.x*blockDim.y+ threadIdx.y*blockDim.x+ threadIdx.x; return threadId; } // 3D grid of 3D blocks __device__ int getGlobalIdx_3D_1D(){ int blockId = blockIdx.z*gridDim.x*gridDim.y + blockIdx.y*gridDim.x+ blockIdx.x; int threadId = blockId*blockDim.x*blockDim.y*blockDim.z+ threadIdx.z*blockDim.x*blockDim.y+ threadIdx.y*blockDim.x+ threadIdx.x; return threadId; } ","date":"2021-08-21","objectID":"https://maxwellf1.github.io/2021-08-21/:7:1","series":null,"tags":["Udacity","CUDA","HPC"],"title":"Udacity CS344-Intro to Parallel Programming-Unit1-The GPU Programming Model","uri":"https://maxwellf1.github.io/2021-08-21/"},{"categories":["AI"],"content":"Chapter 1-But what is a Neural Network 以识别数字的例子进行引入，人脑可以将看到的不同形状写法的数字分辨成0-9的某一个，但是如何让机器程序来解决？ 将这个问题描述为：编写一个程序，输入是一个28×28像素的网格，输出0到9之间的某个数字。 这个对于人眼和大脑都非常容易的问题，对于程序却不好描述，比如传统的if语句、类、对象等等。神经网络则试图编写一个模仿大脑的程序来解决这些问题。 ","date":"2021-08-14","objectID":"https://maxwellf1.github.io/2021-08-14/:1:0","series":null,"tags":["3Blue1Brown","Neural Networks","AI"],"title":"3Blue1Brown-Neural Networks","uri":"https://maxwellf1.github.io/2021-08-14/"},{"categories":["AI"],"content":"神经网络的结构 神经网络多种多样，例如图像处理中广泛使用的CNN，还有RNN和transformer等。我们从最简单最经典的模型来考虑，即多层感知机Plain vanilla(aka “multilayer perceptron”) 神经元 首先将神经元考虑为一个“装有数字的容器”，0.0-1.0之间的值表示被激活的“程度”，来类比人脑中神经元的活跃程度。一堆连接在一起的神经元就构成了神经网络。 对于本问题，输入图像中有28 × 28 = 784个像素，每一个的亮度值都介于0.0和1.0之间，因此我们在网络中对应设计一个有784个神经元的 “输入层” ，同样的最后一层的 “输出层” 包含10个神经元，代表0-9中某个可能的数字。从图中可以看出，在中间还会有一些层，即 “隐含层” ，涉及到一些处理，在图中的网络中设计了2个隐含层，每一层有16个神经元，设置可以是任意的，可以根据情况选择层数和神经元数。 层(Layers) 为什么需要Layers？可以从图中看到某一层的每个神经元会通过一条线连接到下一层的每一个神经元，通常这些线是带有权重的，表示某层中每一个神经元的\"activation\"(激活)如何对下一层的每个神经元的激活产生影响。而确定这些权重的选择，是神经网络作为信息处理机制。我们需要考虑几个问题：为什么期望这样的分层结构能够智能运行？我们期待什么？中间层做的是什么？为什么不直接把所有像素连接到最终输出？ 先从一个 不一定正确 的想法谈起，我们可以希望倒数第二层的每个神经元识别出组成数字的更小的、可识别的组件，比如圆圈，长线段等等，并希望第二层可以对应一些更小的组分，如下图所示： 虽然事实可能与我们这种猜想不同，但我们可以推断到的是，层将问题分解为一些很小的“碎片”。除了图像处理外，解析语音也会用到分层，例如先讲原始音频解析为不同的声音，然后组合成某些音节，再结合成单词，进一步构成短语以及更想法等。因此，神经网络的分层结构是很棒的，它允许我们将困难的问题分为bite-size steps，因此从一层移动到下一层相对会简单一些。 ","date":"2021-08-14","objectID":"https://maxwellf1.github.io/2021-08-14/:1:1","series":null,"tags":["3Blue1Brown","Neural Networks","AI"],"title":"3Blue1Brown-Neural Networks","uri":"https://maxwellf1.github.io/2021-08-14/"},{"categories":["AI"],"content":"信息在层之间的传递 在神经元之间的连线上分配权重，代表着该层的神经元与下一层的新神经元如何相关。如果该层的某个神经元是激活的，正权重代表着与之相连的下一层神经元也应该是激活的，负权重则相反。各个权重会以一种有趣的方式相互作用和冲突。得到第二层的神经元的值需要计算第一层所有神经元激活值的加权和。我们自然可以想到如果我们想找某一块中是否有某一个小“碎片”，不妨将目标区域对应的权重都设为正值，其它赋值为零，这样的确在目标区域有我们希望的“碎片”时更容易将下一层的神经元激活，但是设想一种输入像素全都是激活(纯白)的图像，这种方法的计算结果仍然是“激活”，所以我们如果真的想确定这存在着一条短边(“碎片”)，需要给目标区域周围一圈的权重赋值为负，这样当目标区域像素亮而周围像素暗的时候，综合将最大，例如对于下图的例子中，激活程度B\u003eD\u003eA\u003eC. Sigmoid Squishification \u0026 Bias 上述加权和可能是任何一个数，但是对于该网络我们希望激活值处于0.0-1.0之间，所以需要对得到的结果进行“压缩”。sigmoid是其中一个常用的函数。 但我们希望的可能并非是在大于零时将神经元激活，可能希望加权和大于某个设定值再让其激活，所以我们可以引入Bias，计算公式为： $$ \\sigma(\\omega_{1}a_{1} + \\omega_{2}a_{2} + … +\\omega_{n}a_{n} + Bias) $$ 可以得出，权重告诉我们第二层的神经元关注什么样的pixel pattern，而Bias告诉我们加权和需要多大才认为神经元的激活有意义。 注：sigmoid是有很明显的缺点的。从图中可以看出在数变得极大或者极小时这个函数的变化非常平坦，这不利于我们训练网络。因为当我们调整权重的时候，可能根本没有明显的变化。所以当前广泛采用ReLU(Rectified Linear Unit)。它的输出永远不会变平缓，因此调整权重总能够提供有效的反馈，使得训练过程更快更高效，尤其是设计的层数很多时(深度学习)。 我们采用sigmoid/ReLUd的原因是如果我们单纯的计算加权和，整个函数会是线性的，这会使得网络dramatically less expressive。 More neorons 刚刚是针对一个神经元讨论，但第一层就有784个神经元，则与第二层之间有784×16个权重和16个Bias，加上其它层，权重和偏差加起来一共有13002个，也就是说我们需要针对很大规模的参数进行调节。在之前提到我们对于网络工作模式的设想不一定是正确的，但比起将隐含层当成一个黑箱，这样通过设想来猜测意义，可以对我们修正结构有方向性的帮助。理想情况下网络既能够正确工作，我们也能知道结构设计和参数的缘由。可以通过一些简化的记号通过矩阵的写法来表示众多的参数，这也利于编程： ","date":"2021-08-14","objectID":"https://maxwellf1.github.io/2021-08-14/:1:2","series":null,"tags":["3Blue1Brown","Neural Networks","AI"],"title":"3Blue1Brown-Neural Networks","uri":"https://maxwellf1.github.io/2021-08-14/"},{"categories":["AI"],"content":"网络只是一个函数 之前提到将神经元看做保存数字的容器，其实将其视为一个函数更加准确，它的输入是上一层神经元的所有输出，它的输出是一个0-1之间的值，而图示的整个网络，可以看做输入784的值，输出10个值的函数。 ","date":"2021-08-14","objectID":"https://maxwellf1.github.io/2021-08-14/:1:3","series":null,"tags":["3Blue1Brown","Neural Networks","AI"],"title":"3Blue1Brown-Neural Networks","uri":"https://maxwellf1.github.io/2021-08-14/"},{"categories":["AI"],"content":"Chapter2 Gradient descent, how neural networks learn 梯度下降法是训练的核心思想，不仅是神经网络学习的基础，也是其它许多机器学习技术的基础。 ","date":"2021-08-14","objectID":"https://maxwellf1.github.io/2021-08-14/:2:0","series":null,"tags":["3Blue1Brown","Neural Networks","AI"],"title":"3Blue1Brown-Neural Networks","uri":"https://maxwellf1.github.io/2021-08-14/"},{"categories":["AI"],"content":"网络如何学习 机器学习与其它计算机科学的不同之处在于，我们没有为执行特定任务编写指令。对于第一节的例子，我们没有编写识别数字的算法，相反我们编写了一个可以接收一堆手写数字的示例图像以及它们是什么的标签的算法，并且调整网络的13002个参数(输入的标记图像称为“训练数据”)。我们通过这些数据来训练网络，然后使用一些网络没见过的数据在训练后对其进行测试。 机器的学习过程更像是一个微积分的问题，它目的是找到特定函数的最小值。 成本函数 现在很多时候将cost/lost function混为一谈。回顾一下，加权值和中的权重可以认为代表连接的强弱，而偏置值则表明神经押元是否更容易被激活。首先将所有权重和偏差初始化为随机数，网络会表现很糟，需要设计一种方式来识别目前做的很糟糕，然后帮助它改进。所以我们来定义一个成本函数，将输出与期望值之间的差异平方相加，称为该训练数据的“成本”。 The Cost Over Many Examples 为了真正衡量网络的性能，我们要考虑所有(可能数万个)训练示例的平均成本，这个平均值是我们衡量网络有多糟糕以及计算机应该感觉有多糟糕的指标。同样的，这个平均成本也是一个复杂的函数，网络本身就是一个复杂的函数，平均成本(代价函数)要再网络的基础上进行更高一层的计算，它将13002个权重和偏置值作为其参数，而输出一个数值(差的平方和)。 Minimizing the cost function 告诉计算机有多么糟糕只是一部分，我们更需要告诉它应该如何改进。对于简单的函数，我们可以通过求导，来知道在什么位置可以取到(局部)最小值，但对于复杂的函数，本次实例中上万个参数的函数，是无法这样进行的。一个更灵活的技巧是，先随便挑一个输入值，然后考虑往什么方向走，可以将函数值减小，这样在每一个点都求梯度，并沿着下降的方向走一小步(斜率越小这个步长就越小，从而防止调整过度)，就可以逼近函数的某个局部最小值(可能存在很多，取决于从哪个随机输入开始)，可以想象成小球从山上往下滚。 梯度 在高维空间中我们需要一个向量来表示最陡峭的方向，多元微积分中将这个向量称为”梯度“，代表哪个方向增加函数最快，取该向量的反方向就可以得到最快减小函数的步进方向，这个梯度向量的长度表示了这个最陡的斜坡有多陡。所以最小化这个函数的算法是计算这个梯度方向，然后下降，不断重复，这个过程就叫做”梯度下降“。 如果我们把这13002个权重和偏置值都放到一个列向量里，则代价函数的(负)梯度也会是一个有13002个条目的向量。 负梯度指出了我们应该如何调整每个参数，才可以让代价函数的值下降的最快。该向量的每个分量告诉我们两件事，符号表示相应分量应该向上还是向下，更重要的一点是，梯度中各个分量的相对大小告诉我们这些调整哪一个更为重要(改变哪个性价比更高)。计算梯度的算法是神经网络的核心，称为back propagation(反向传播算法)。 注意，我们一直提到寻找最小值，这要求代价函数必须是平滑的，这也解释了为什么人工神经元的激活值是连续的，而不是二元式。 回顾一下我们之前设想的，第二层识别一些小的“碎片”，第三层识别更大一些的pattern，但事实上这个网络本身并不是这样做的，第二层的结果看起来会杂乱无章，只是代表某个局部最小值而已。而且因为我们的训练数据只有从0-9的标签数据，相当于整个空间只局限于此，所以训练好的网络也可能将某个毫无意义的噪声图像识别为某个数字。当然MLP只是一个很古老的模型，现在有更多更好用的新模型出现。 ","date":"2021-08-14","objectID":"https://maxwellf1.github.io/2021-08-14/:2:1","series":null,"tags":["3Blue1Brown","Neural Networks","AI"],"title":"3Blue1Brown-Neural Networks","uri":"https://maxwellf1.github.io/2021-08-14/"},{"categories":["AI"],"content":"Chapter 3-Analyzing our neural network 这是一个mini lesson。将分析训练好的网络做了什么以及原因。之前例子中的网络训练好后大概有96%的正确率，这其实是难以置信的，因为我们从来没有明确告诉它要寻找怎么样的pattern。 之前我们猜测第二层识别小的边缘，第三层识别更大一些的子组件来激发这个结构。但事实上我们的网络不是这样的，查看从第一层到下一层的过度相关联的权重时，它们看起来几乎是随机的，虽然有一些松散的pattern，但显然不是我们之前设想的： 似乎在可能权重和偏差的13002维空间中，网络发现了某一个局部最小值，尽管成功的对大多数图像进行了分类，但并没有完全掌握更普遍的模式，例如之前提到的随机输入一个噪声图像，智能的系统应该输出不确定的结果(要么没有激活，要么均匀激活输出层)，但其实它自信的给出了一些无意义的答案。而且这个网络的训练数据基本都是居中且大小合适的数字，并没有让网络在网格的一个区域上获取的模式知识转移到另一个区域，我们的训练算法甚至没有使用某些像素和其他像素相邻的事实。 ","date":"2021-08-14","objectID":"https://maxwellf1.github.io/2021-08-14/:3:0","series":null,"tags":["3Blue1Brown","Neural Networks","AI"],"title":"3Blue1Brown-Neural Networks","uri":"https://maxwellf1.github.io/2021-08-14/"},{"categories":["AI"],"content":"Chapter4-What is backpropagation really doing ","date":"2021-08-14","objectID":"https://maxwellf1.github.io/2021-08-14/:4:0","series":null,"tags":["3Blue1Brown","Neural Networks","AI"],"title":"3Blue1Brown-Neural Networks","uri":"https://maxwellf1.github.io/2021-08-14/"},{"categories":["AI"],"content":"The Intuition for Backpropagation 反向传播中的各种符号和上下标一开始会使人困扰。首先我们忽略这些公式符号，从逐步了解每个训练示例对权重和偏差的影响开始。 对于这个样本，我们希望网络分类为2，我们希望输出值的变动大小应该与当前值和目标值之间的差异成正比，例如，增加数字“2”神经元的激活值要比减少数字“8”的激活值更为重要，因为后者已经接近理想输出。我们以“2”神经元为例： 它的激活值是来自于前一层所有的加权综合，加上一个偏置值，最后经过sigmoid/ReLU等进行处理。因此我们有三种方法来增大这个激活值： 增加偏置值 增加权重 改变上一层的激活值 增加偏置值 这是最简单的方法，与改变前一层的权重或者激活值不同，改变偏置对加权和的影响是恒定而且可预测的。 增加权重 权重与激活值相乘，所以具有不同程度的影响，与来自前一层更亮的神经元的连接具有较大的影响，因为这些权重与更大的激活值相乘。即当我们进行梯度下降时，不仅关心每个是要向上还是向下调整，更关心调整哪些参数性价比最高。 这里类似于神经科学中关于神经元如何学习的理论——“赫布理论(Hebbian theory)”，即“一同激活的神经元关联在一起”。这里，权重的最大增长，即最大的连接加强的部分，就会发生在已经最活跃的神经元和我们希望变得更活跃的神经元之间。 改变前一层的激活值 如果前一层中所有正权重连接的神经元更亮而负权重连接的神经元更暗的话，就可以增加我们想要的神经元的激发程度。与改变权重的时候类似，我们想造成更大的影响，就要根据对应权重的大小，对激活值做出成比例的改变。当然，我们无法直接改变激活值。 ","date":"2021-08-14","objectID":"https://maxwellf1.github.io/2021-08-14/:4:1","series":null,"tags":["3Blue1Brown","Neural Networks","AI"],"title":"3Blue1Brown-Neural Networks","uri":"https://maxwellf1.github.io/2021-08-14/"},{"categories":["AI"],"content":"对所有的训练数据重复 我们之前只考虑了要增强2的激活，但还要减弱最后一层中其他神经元的激活。但每个神经元对于如何改变倒数第二层都有自己的想法，这意味着有许多竞争性的请求来改变前一层。所以我们会将数字“2”神经元的期待和其它输出神经元的期待全加在一起，作为如何改变倒数第二层神经元的指示。这些期待的变化不仅与对应的权重成比例，也与每个神经元激活值需要改变的量成比例。这其实就是“反向传播”的理念，我们可以一直递归的将这个过程进行从后一层到前一层，直到第一层。 刚刚我们讨论的是仅仅对一个训练样本进行的过程，我们还需要对其他所有的训练样本同样的进行一遍反向传播。记录下每个样本想要怎样修改，然后取平均值。 这里一系列的对每个权重和偏置的平均微调大小，不严格的讲，就是之前说的代价函数的负梯度(至少是其标量的倍数)。 ","date":"2021-08-14","objectID":"https://maxwellf1.github.io/2021-08-14/:4:2","series":null,"tags":["3Blue1Brown","Neural Networks","AI"],"title":"3Blue1Brown-Neural Networks","uri":"https://maxwellf1.github.io/2021-08-14/"},{"categories":["AI"],"content":"Stochastic Gradient Descent 实际操作中如果梯度下降的每一步都用上每一个训练样本来计算会非常耗时。可以采取一个技巧，首先将训练数据打乱并分成很多组minibatch。然后根据每个minibatch而不是整个训练样本集来计算梯度下降。它并不会提供准确最有效的梯度下降，但给出了一个很好的近似值，而且计算时间大大减少，这就是随机梯度下降。我们并不是小心谨慎的一步步沿着最佳方向走到底部，而是有点像个醉汉快速但是绕着小圈子跑下去。 注：我们需要非常多的标记好的数据才能良好的完成训练过程。 ","date":"2021-08-14","objectID":"https://maxwellf1.github.io/2021-08-14/:4:3","series":null,"tags":["3Blue1Brown","Neural Networks","AI"],"title":"3Blue1Brown-Neural Networks","uri":"https://maxwellf1.github.io/2021-08-14/"},{"categories":["AI"],"content":"Chapter5-Backpropagation calculus 从微积分的角度看在机器学习中我们一般是怎么理解链式法则的。 梯度向量的条目是代价函数相对于网络所有不同权重的偏置的偏导数，也就是说反向传播帮我们计算出了那些导数。 ","date":"2021-08-14","objectID":"https://maxwellf1.github.io/2021-08-14/:5:0","series":null,"tags":["3Blue1Brown","Neural Networks","AI"],"title":"3Blue1Brown-Neural Networks","uri":"https://maxwellf1.github.io/2021-08-14/"},{"categories":["AI"],"content":"用反向传播计算梯度 首先我们设定一些记号： a(L) 表示L层某个神经元的激活值，y是我们期待的输出，C0是代价函数，我们想知道在数轴上挪动ω可以对C造成多大影响，就是求导，可以利用链式法则。 网络的完整代价函数是求的每个样本的平均值，所以导数我们也要求平均值。而这个只是梯度向量的一个分量，所有权重和偏置的导数组成梯度向量。从求导结果我们可以看出，当前一个神经元更活跃时(a(L-1))，改变ω可以有更好的效果，偏导的最后一部分告诉我们该导数与实际输出与期望输出之间的差异成正比，也就是说当实际输出偏差很大时，即使微小的改动也会对代价产生明显的影响。 偏置的梯度更简单一些： ","date":"2021-08-14","objectID":"https://maxwellf1.github.io/2021-08-14/:5:1","series":null,"tags":["3Blue1Brown","Neural Networks","AI"],"title":"3Blue1Brown-Neural Networks","uri":"https://maxwellf1.github.io/2021-08-14/"},{"categories":["AI"],"content":"前一层的权重和偏置 我们已经确定了最后一层的权重和偏置的变化如何影响总体的成本，这意味着我们已经有了梯度向量的两个部分(前面提到三种改变方式)。现在我们要探讨一下代价函数对上一层激活值的敏感程度(对a(L-1)求偏导)。虽然我们不能直接改变激活值，但我们仍应该关注这一方面，因为我们可以反向利用链式法则，来计算代价函数对之前(前一层)的权重和偏置的敏感度。 例如求偏导$\\frac{\\partial(C_0)}{\\partial(w^{(L-1)})}$​​​可以通过如下的链式法则得出，因此我们可以通过链式法则得到任何一个参数的导数，即可以计算出整个梯度向量的各个分量。 $$ \\frac{\\partial(C_0)}{\\partial(w^{(L-1)})}=\\frac{\\partial(z^{(L-1)})}{\\partial(w^{(L-1)})}\\frac{\\partial(a^{(L-1)})}{\\partial(z^{(L-1)})}\\frac{\\partial(z^{L})}{\\partial(a^{(L-1)})}\\frac{\\partial(a^{L})}{\\partial(z^{L})}\\frac{\\partial(C_0)}{\\partial(a^{L})} $$ ","date":"2021-08-14","objectID":"https://maxwellf1.github.io/2021-08-14/:5:2","series":null,"tags":["3Blue1Brown","Neural Networks","AI"],"title":"3Blue1Brown-Neural Networks","uri":"https://maxwellf1.github.io/2021-08-14/"},{"categories":["AI"],"content":"更复杂的网络 上面的例子中是“一条线”的简单网络，对于复杂网络其实没有太大变化，只是多了一些下标而已，来指出这是该层的哪个神经元对应的量。而代价函数和对于上一层激活值的偏导变成了求和的模式： 可以用下面的公式总结，对于下面黄色框的公式，当不是最后一层的时候用上式，是最后一层用下式。 ","date":"2021-08-14","objectID":"https://maxwellf1.github.io/2021-08-14/:5:3","series":null,"tags":["3Blue1Brown","Neural Networks","AI"],"title":"3Blue1Brown-Neural Networks","uri":"https://maxwellf1.github.io/2021-08-14/"},{"categories":["Tools"],"content":"1. 连接 通过SSH，首先需要确定自己已经安装了openSSH，本次是在Windows环境下进行。选用自己习惯的软件即可，我用过putty, Xshell, VScode等等，由于自己太懒配置不好vim，而且终端看久了眼疼，就想采用VS Code来进行连接。 ","date":"2021-08-12","objectID":"https://maxwellf1.github.io/2021-08-12/:1:0","series":null,"tags":["Server"],"title":"远程服务器连接","uri":"https://maxwellf1.github.io/2021-08-12/"},{"categories":["Tools"],"content":"通用流程 安装SSH和VS code，并在VS code的扩展商店里添加Remote SSH相关插件。 生成密钥。在.ssh目录下可以用ssh-keygen命令生成公钥和私钥，并将公钥传到远程服务器的根目录下.ssh文件夹中。 连接远程主机(例如通过ssh username@ip -p port命令)，在.ssh目录下通过cat xxx.pub \u003e\u003e authorized_keys命令将公钥添加到authorized_keys中。 采用私钥进行登录(例如ssh username@ip -p port -i id_rsa命令)。点击VS code中Remote SSH的设置键，通常选第一个configuration file进入，根据需要填写下面的参数信息： Host: 连接的主机的名称，可以自己起名 Hostname: remote server的IP地址 Port: 用于登录远程服务器的端口 User: 用于登录远程主机的用户名 IdentityFile: 私钥在本地的路径 ProxyCommand: 需要执行的指令 完成并保存后就可以发现在左侧添加上的新的远程服务器，点击连接即可。 ","date":"2021-08-12","objectID":"https://maxwellf1.github.io/2021-08-12/:1:1","series":null,"tags":["Server"],"title":"远程服务器连接","uri":"https://maxwellf1.github.io/2021-08-12/"},{"categories":["Tools"],"content":"跳板机 有时候例如自己实验的的服务器是设置在内网环境中的，用自己的客户端在公共环境无法直接连接，通常采用跳板机来解决这个问题。一般是先通过ssh连接到跳板机之后，再跳转到所需的服务器，同样是只能用vim使用命令行环境，由于配置起来比较麻烦，使用不便，还是想用VS code来提高便捷性。配置的过程与通用流程稍有不同，因为涉及到两个机器，所以在configuration files中要按照如下方式填写： Host JumpMachine #跳板机名称 HostName XXX.XXX.XXX.XXX #跳板机IP Port XXX #跳板机ssh端口 User root #跳板机用户名 IdentityFile xx\\xx\\xx.. Host TargetMachine #远程服务器名称 HostName XXX.XXX.XXX.XXX #远程服务器IP Port XXX #远程服务器ssh端口 User root #远程服务器用户名 ProxyCommand ssh(替换为自己安装的ssh的路径，例如C:\\Windows\\System32\\OpenSSH\\ssh.exe) -W %h:%p JumpMachine 同样的，为了省去密码等，可以发送公钥到跳板机和服务器，并添加到authorized_keys中(并在参数中添加IdentityFile)。(注：所有前序机器的id_rsa.pub都要添加到最终机器上。比如说有3台机ABC，其中B是跳板机。那么A的.pub要在B跟C上分别导入一次，B的.pub要在C上导入一次，共3次，才能完全实现免密登录远程服务器) 为了防止发送公钥时覆盖了目标机器上的authorized_keys文件，可以用ssh-copy-id命令来复制公钥 ssh-copy-id -i id_rsa.pub \"-p 跳板机的ssh端口 用户名@跳板机IP\" 将笔记本的公钥也同样的发送到远程服务器中 可以先使用scp将公钥发送至跳板机 scp -P 跳板机ssh端口 id_rsa.pub 跳板机用户名@跳板机IP:~/.ssh/temp 再通过ssh连接至跳板机，并切换到~/.ssh目录下，将其发送至远程服务器 scp -P 远程服务器ssh端口 temp 远程服务器用户名@远程服务器IP:~/.ssh/temp 最后通过ssh连接至远程服务器，切换到~/.ssh目录下，手动将公钥拼接到authorized_keys中 cat temp \u003e\u003e authorized_keys 配置保存后就可以在左边的SSH TARGETS中看到配置好的JumpMachine和TargetMachine，选择TargetMachine进行连接即可。 ","date":"2021-08-12","objectID":"https://maxwellf1.github.io/2021-08-12/:1:2","series":null,"tags":["Server"],"title":"远程服务器连接","uri":"https://maxwellf1.github.io/2021-08-12/"},{"categories":["Tools"],"content":"2. 文件传输 个人由于懒而且记不住命令还是比较习惯有GUI，平时比较常用的是WinSCP,这是一个在Windows环境下使用的SSH的开源图形化SFTP客户端，同时支持SCP协议。它可以在本地与远程计算机之间安全的传输文件，并可以直接编辑文件。它可以很直观的看到文件的层级结构和控制文件的传输而无需依赖其它插件。 ","date":"2021-08-12","objectID":"https://maxwellf1.github.io/2021-08-12/:2:0","series":null,"tags":["Server"],"title":"远程服务器连接","uri":"https://maxwellf1.github.io/2021-08-12/"},{"categories":["Tools"],"content":"基本使用 新建会话主机名填入IP，端口号填入自己的端口号，再输入用户名和密码，保存并登陆之后应该可以看到文件的界面。 ","date":"2021-08-12","objectID":"https://maxwellf1.github.io/2021-08-12/:2:1","series":null,"tags":["Server"],"title":"远程服务器连接","uri":"https://maxwellf1.github.io/2021-08-12/"},{"categories":["Tools"],"content":"跳板机 在session界面点击高级选项，在高级设置中找到隧道/Tunnel，勾选上使用SSH隧道，并输入跳转机的IP、端口号以及用户名和密码，如果不输入密码，可以在Tunnel界面下方添加自己的私钥文件(需要是ppk，如果不是可以用PuTTYgen来生成/转换)。登录界面的信息填最终想通过跳转机连接到的服务器的配置即可。 ","date":"2021-08-12","objectID":"https://maxwellf1.github.io/2021-08-12/:2:2","series":null,"tags":["Server"],"title":"远程服务器连接","uri":"https://maxwellf1.github.io/2021-08-12/"},{"categories":["Tools"],"content":"命令 scp是secure copy的简写，用于在Linux下进行远程拷贝文件的命令，和它类似的命令有cp，不过cp只是在本机进行拷贝不能跨服务器，而且scp传输是加密的。可能会稍微影响一下速度。当你服务器硬盘变为只读 read only system时，用scp可以帮你把文件移出来。另外，scp还非常不占资源，不会提高多少系统负荷，在这一点上，rsync就远远不及它了。虽然 rsync比scp会快一点，但当小文件众多的情况下，rsync会导致硬盘I/O非常高，而scp基本不影响系统正常使用。 当在同一个服务器不同账户之间传输文件时可以用scp命令。例如想把服务器下B用户目录下的某文件b拷到A用户目录下，可以采用如下指令 scp -r dir_B/b serverIP:/dir_A 具体命令及参数可以见参考文献的几个链接。 ","date":"2021-08-12","objectID":"https://maxwellf1.github.io/2021-08-12/:2:3","series":null,"tags":["Server"],"title":"远程服务器连接","uri":"https://maxwellf1.github.io/2021-08-12/"},{"categories":["Tools"],"content":"一些问题 vscode提示例如“unsupported zsh”等unsupported terminal launch等情况。 通常是因为设置中默认的shell服务器端不支持。根据参考链接8，可以打开vscode的terminal 相关settings。例如把\"terminal.integrated.shell.linux\": \"/bin/zsh\"修改为.../bash。 ","date":"2021-08-12","objectID":"https://maxwellf1.github.io/2021-08-12/:3:0","series":null,"tags":["Server"],"title":"远程服务器连接","uri":"https://maxwellf1.github.io/2021-08-12/"},{"categories":["Tools"],"content":"参考文献 VS Code Remote SSH配置 vscode通过跳板机连接远程服务器_huitailangyz的博客-CSDN博客 使用WinScp连接远程服务器和传输文件 - 你要 - 博客园 (cnblogs.com) winscp通过跳板机访问远程服务器（使用秘钥的方式传输文件） - 华为云 (huaweicloud.com) Linux scp -r命令主机间文件复制_学亮编程手记-CSDN博客 scp详解_LZJWXJ树袋熊-CSDN博客 Linux在同一台服务器不同账号之间传输文件_蓝一潇的博客-CSDN博客 Troubleshoot Visual Studio Code Integrated Terminal launch failures ","date":"2021-08-12","objectID":"https://maxwellf1.github.io/2021-08-12/:4:0","series":null,"tags":["Server"],"title":"远程服务器连接","uri":"https://maxwellf1.github.io/2021-08-12/"},{"categories":[],"content":"1.为什么建立这个博客 博客这玩意儿，应该很早以前就有了。记得我上小学的时候老师们通过某个叫“校讯通”的平台建立了博客，有时候会发布一些信息，记录一些班级事务之类的。当时我也跟风，没记错的话是在网易建立了自己的博客，还各种费心思换主题，有水墨、竹林、牛皮纸等(🤣。后来也就当成了一个玩具一样，改个配色，改个字体，也没有当成个正事儿，最后随着各种新兴事物的出现，早就把写博客这档子事儿抛到九霄云外去了。 我从来不喜欢动手记录，例如中学的时候老师一遍又一遍的反复教育我整理错题和笔记，我却感觉这是浪费时间，完全不弄或者随便糊弄几笔了事儿。大学时候。我仍然引以为傲的保持着自己的“优良传统”，其实逐渐感觉到吃力了，毕竟这些课程比中学那点知识不知道高到哪里去了，但为了保持自己可笑的“独特习惯”，我就是不愿意记笔记，作业也是写完就了事儿，逐渐出现了很多自己一次又一次记不住的知识，写不对的题，敲不出来的code。还带着之前的思维，毕竟中学总觉得自己挺聪明，效率高，而且现在自己这么混，都没有挂科，成绩还能凑合中等，“要是我努努力，细心一点，肯定能变得很厉害，我只是不愿意罢了”。其实那个时候，我开始发觉自己已经眼高手低了，只是心底里想逃避罢了，“要是我更用心，反而没什么提高，别人会不会笑话我效率低，笑话我是个笨蛋呢”，所以还是保持着陋习。2018年我还看了姜文的电影，《邪不压正》，开玩笑的跟哥们说道：“正经人谁记笔记啊？是啊。你记笔记吗？我不记，你记笔记吗？谁能把学会的写笔记里？写出来的能叫学会的？下贱！”👎更觉得记东西反而是浪费时间，会了就是会，不会的咋着都学不会🤡 后来，一些事情改变了我，我开始意识到自己的不足，也决定尝试改变，摆正自己的定位，做一些自己之前看不上眼的事儿来补救。但仍然觉得很低效，看似自己在忙活着，一段时间过后回想起来，感觉自己还是什么都没学会，再遇到同样的问题时，很多时候还是要重新查，一直没想到该怎么解决这个问题。最近看到网上的推荐，读了Philip J.Guo的The Ph.D. Grind，感触颇深，想不错的完成博士学业确实是一门学问，无论是身心还是自己的学术技能都要不断的经受Grind，但如何度过好这个训练的过程，让这些grind变得有意义，是读博应该思考的。其实这一年来我也在思考类似的问题，也找了很多长辈和同辈讨论，后来总结出 “反馈” 大概对于很多人至少对于我是很重要的。一方面我很畏惧没头没尾的不踏实感，有反馈才能更好的证明“存在”；另一方面，费曼学习法中通过自己的总结和他人的反馈，能够帮助自己更好的消化知识，或者触发新的灵感。 因此，我选择开始写博客来记录。这样回过头来可以大概知道自己学到或者曾经接触了些什么，还能在不断的回顾中加深印象，查漏补缺。我再也不想因为一些幼稚的想法而耽误自己，努力，永远不嫌早，也永远不会太晚。 ","date":"2021-08-11","objectID":"https://maxwellf1.github.io/2021-08-11/:1:0","series":null,"tags":[],"title":"写在开始的话","uri":"https://maxwellf1.github.io/2021-08-11/"},{"categories":[],"content":"2.一些说明 ","date":"2021-08-11","objectID":"https://maxwellf1.github.io/2021-08-11/:2:0","series":null,"tags":[],"title":"写在开始的话","uri":"https://maxwellf1.github.io/2021-08-11/"},{"categories":[],"content":"2.1关于本博客 本博客基于HUGO的DoIt主题创建。 Title的icon采用了earlybirds，以激励自己笨鸟先飞。 主页的subtitle\"觉悟者恒幸福\"是jojo的奇妙冒险第六部石之岛中恩里克普奇神父说的一句话，我赞同这句话，但我并不认为普奇神父自己做到了这一点，相对于他，布加拉提、米斯达、乔鲁诺等人应该都是这句话更好的践行者。其实这不过是老生常谈的宿命论，但如何看待，如何行动会收获不一样的心境和结果，就像茸茸说的那样，所谓觉悟，不是牺牲的心，而是在黑暗的荒野中开辟出一条前进的道路。我希望自己能成为一个有觉悟的人，不为自己看到的所谓“宿命”而哀叹或者是丧气的接受，而是不断追求。 ","date":"2021-08-11","objectID":"https://maxwellf1.github.io/2021-08-11/:2:1","series":null,"tags":[],"title":"写在开始的话","uri":"https://maxwellf1.github.io/2021-08-11/"},{"categories":[],"content":"2.2 关于一些事情 博客的title叫Separator，Wiki词条中对它有更详细的说明。大概是两年前(2019年底2020年初)的样子我给自己想到了这个NickName，自以为很妙，我很喜欢这个代号。一方面和我的名字有一定的联系，另一个方面，它也说明了我的转变，也是我努力的方向。 应该是那年某学期选课的时候，和本科导师聊过几句，每次见面的时候他都是鼓励我，那次也不例外，但有些话大概是作为第一个分隔符的存在，让我的心态发生了转变。那次突然想和老师聊聊未来的规划，就不怕丢人的说了一些自己的情况和想法，也斗胆问了一下老师当年的故事。他居然很乐意和我聊这些，先肯定了我的一些想法，也告诉我他自己当年也有过迷茫的时候，但一个人要做的并不是封闭自我或者自暴自弃，而是要迫使自己接触更多的东西，去做更多的尝试，同时也更努力的去做一些目前应该做好的事儿，他说只要这样，就算我考试60分甚至不及格，在他心里都是一个很优秀的本科生。我当时的成绩是在系里很下游，已经太久没有跟“优秀”沾过边了，老师说的话刺痛了我也点醒了我，我之前所做的那些不过是逃避和借口罢了。 从那学期开始，我决心多学多看多钻研，也开始做那些之前觉得笨学生才会做的事情，因为我明白，自己已经是一个又笨基础又差的学生了。应该是在那个学期，我拿到了大学以来第一个专业课90+，从此之后，第二个、第三个…, 92、95、99…，那几个学期九十左右的均分也让我最终奇妙的获得了保研资格。还主动进组体验了几次科研，并且发表了一篇短文，虽然只是在一个规模很小的Workshop上，但也算长了长见识。这里，又是一个分隔符，我不再看不起这些那些，开始鼓励自己多去尝试，“不试试怎么知道行不行呢”，“人总要有梦想的，万一实现了呢”。 后来发生了更多奇妙的事情，也遇到了很多贵人帮助，让我划上了一个又一个的分隔符，心理和状态不断进入新的阶段。非常感谢这些人这些事儿❤️。我也深知，在以后的日子里，大概会划上更多新的分隔符，但是新阶段的情况和走向如何，才是我应该考虑并为之努力的。此外，Separator另一个意思为分离的装置，希望在以后的日子里，我能将知识、项目、乃至生活等等都做出一个好的分离，清晰透彻的观察问题，并将各组分做良好的拆分，安排好、解决好各种事务。 ","date":"2021-08-11","objectID":"https://maxwellf1.github.io/2021-08-11/:2:2","series":null,"tags":[],"title":"写在开始的话","uri":"https://maxwellf1.github.io/2021-08-11/"}]